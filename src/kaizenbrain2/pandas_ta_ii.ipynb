{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "import mplfinance as mpf\n",
    "from pyclustering.cluster.silhouette import silhouette_ksearch_type, silhouette_ksearch\n",
    "from pyclustering.cluster.kmeans import kmeans\n",
    "from pyclustering.cluster.center_initializer import kmeans_plusplus_initializer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_pips(data: np.array, n_pips: int, dist_measure: int):\n",
    "    # dist_measure\n",
    "    # 1 = Euclidean Distance\n",
    "    # 2 = Perpindicular Distance\n",
    "    # 3 = Vertical Distance\n",
    "\n",
    "    pips_x = [0, len(data) - 1]  # Index\n",
    "    pips_y = [data[0], data[-1]] # Price\n",
    "\n",
    "    for curr_point in range(2, n_pips):\n",
    "\n",
    "        md = 0.0 # Max distance\n",
    "        md_i = -1 # Max distance index\n",
    "        insert_index = -1\n",
    "\n",
    "        for k in range(0, curr_point - 1):\n",
    "\n",
    "            # Left adjacent, right adjacent indices\n",
    "            left_adj = k\n",
    "            right_adj = k + 1\n",
    "\n",
    "            time_diff = pips_x[right_adj] - pips_x[left_adj]\n",
    "            price_diff = pips_y[right_adj] - pips_y[left_adj]\n",
    "            slope = price_diff / time_diff\n",
    "            intercept = pips_y[left_adj] - pips_x[left_adj] * slope;\n",
    "\n",
    "            for i in range(pips_x[left_adj] + 1, pips_x[right_adj]):\n",
    "                \n",
    "                d = 0.0 # Distance\n",
    "                if dist_measure == 1: # Euclidean distance\n",
    "                    d =  ( (pips_x[left_adj] - i) ** 2 + (pips_y[left_adj] - data[i]) ** 2 ) ** 0.5\n",
    "                    d += ( (pips_x[right_adj] - i) ** 2 + (pips_y[right_adj] - data[i]) ** 2 ) ** 0.5\n",
    "                elif dist_measure == 2: # Perpindicular distance\n",
    "                    d = abs( (slope * i + intercept) - data[i] ) / (slope ** 2 + 1) ** 0.5\n",
    "                else: # Vertical distance    \n",
    "                    d = abs( (slope * i + intercept) - data[i] )\n",
    "\n",
    "                if d > md:\n",
    "                    md = d\n",
    "                    md_i = i\n",
    "                    insert_index = right_adj\n",
    "\n",
    "        pips_x.insert(insert_index, md_i)\n",
    "        pips_y.insert(insert_index, data[md_i])\n",
    "\n",
    "    return pips_x, pips_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PIPPatternMiner:\n",
    "\n",
    "    def __init__(self, n_pips: int, lookback: int, hold_period: int):\n",
    "        self._n_pips = n_pips\n",
    "        self._lookback = lookback\n",
    "        self._hold_period = hold_period\n",
    "        \n",
    "        self._unique_pip_patterns = []\n",
    "        self._unique_pip_indices = []\n",
    "        self._cluster_centers = []\n",
    "        self._pip_clusters = []\n",
    "\n",
    "        self._cluster_signals = []\n",
    "        self._cluster_objs = []\n",
    "\n",
    "        self._long_signal = None\n",
    "        self._short_signal = None\n",
    "\n",
    "        self._selected_long = []\n",
    "        self._selected_short = []\n",
    "\n",
    "        self._fit_martin = None\n",
    "        self._perm_martins = []\n",
    "        \n",
    "        self._data = None # Array of log closing prices to mine patterns\n",
    "        self._returns = None # Array of next log returns, concurrent with _data\n",
    "\n",
    "    def get_fit_martin(self):\n",
    "        return self._fit_martin\n",
    "\n",
    "    def get_permutation_martins(self):\n",
    "        return self._perm_martins\n",
    "\n",
    "    def plot_cluster_examples(self, candle_data: pd.DataFrame, cluster_i: int, grid_size: int = 5):\n",
    "        plt.style.use('dark_background')\n",
    "        fig, axs = plt.subplots(grid_size, grid_size)\n",
    "        flat_axs = axs.flatten()\n",
    "        for i in range(len(flat_axs)):\n",
    "            if i >= len(self._pip_clusters[cluster_i]):\n",
    "                break\n",
    "            \n",
    "            pat_i = self._unique_pip_indices[self._pip_clusters[cluster_i][i]]\n",
    "            data_slice = candle_data.iloc[pat_i - self._lookback + 1: pat_i + 1]\n",
    "            idx = data_slice.index\n",
    "            plot_pip_x, plot_pip_y = find_pips(data_slice['close'].to_numpy(), self._n_pips, 3)\n",
    "            \n",
    "            pip_lines = []\n",
    "            colors = []\n",
    "            for line_i in range(self._n_pips - 1):\n",
    "                l0 = [(idx[plot_pip_x[line_i]], plot_pip_y[line_i]), (idx[plot_pip_x[line_i + 1]], plot_pip_y[line_i + 1])]\n",
    "                pip_lines.append(l0)\n",
    "                colors.append('w')\n",
    "\n",
    "            mpf.plot(data_slice, type='candle',alines=dict(alines=pip_lines, colors=colors), ax=flat_axs[i], style='charles', update_width_config=dict(candle_linewidth=1.75) )\n",
    "            flat_axs[i].set_yticklabels([])\n",
    "            flat_axs[i].set_xticklabels([])\n",
    "            flat_axs[i].set_xticks([])\n",
    "            flat_axs[i].set_yticks([])\n",
    "            flat_axs[i].set_ylabel(\"\")\n",
    "\n",
    "        fig.suptitle(f\"Cluster {cluster_i}\", fontsize=32)\n",
    "        plt.show()\n",
    "\n",
    "\n",
    "    def predict(self, pips_y: list):\n",
    "        norm_y = (np.array(pips_y) - np.mean(pips_y)) / np.std(pips_y)\n",
    "\n",
    "        # Find cluster\n",
    "        best_dist = 1.e30\n",
    "        best_clust = -1\n",
    "        for clust_i in range(len(self._cluster_centers)):\n",
    "            center = np.array(self._cluster_centers[clust_i])\n",
    "            dist = np.linalg.norm(norm_y-center)\n",
    "            if dist < best_dist:\n",
    "                best_dist = dist\n",
    "                best_clust = clust_i\n",
    "\n",
    "        if best_clust in self._selected_long:\n",
    "            return 1.0\n",
    "        elif best_clust in self._selected_short:\n",
    "            return -1.0\n",
    "        else:\n",
    "            return 0.0\n",
    "    \n",
    "    \n",
    "    def train(self, arr: np.array, n_reps=-1):\n",
    "        self._data = arr\n",
    "        self._returns = pd.Series(arr).diff().shift(-1)\n",
    "        self._find_unique_patterns()\n",
    "        \n",
    "\n",
    "        search_instance = silhouette_ksearch(\n",
    "                self._unique_pip_patterns, 5, 40, algorithm=silhouette_ksearch_type.KMEANS).process()\n",
    "        \n",
    "        amount = search_instance.get_amount()\n",
    "        self._kmeans_cluster_patterns(amount)\n",
    "\n",
    "        self._get_cluster_signals()\n",
    "        self._assign_clusters()\n",
    "        self._fit_martin = self._get_total_performance()\n",
    "        \n",
    "        print(self._fit_martin)\n",
    "\n",
    "        if n_reps <= 1:\n",
    "            return\n",
    "\n",
    "        # Start monte carlo permutation test\n",
    "        data_copy = self._data.copy()\n",
    "        returns_copy = self._returns.copy()\n",
    "        \n",
    "        for rep in range(1, n_reps):\n",
    "            x = np.diff(data_copy).copy()\n",
    "            np.random.shuffle(x)\n",
    "            x = np.concatenate([np.array([data_copy[0]]), x])\n",
    "            self._data = np.cumsum(x)\n",
    "            self._returns = pd.Series(self._data).diff().shift(-1)\n",
    "            print(\"rep\", rep) \n",
    "            self._find_unique_patterns()\n",
    "            search_instance = silhouette_ksearch(\n",
    "                    self._unique_pip_patterns, 5, 40, algorithm=silhouette_ksearch_type.KMEANS).process()\n",
    "            amount = search_instance.get_amount()\n",
    "            self._kmeans_cluster_patterns(amount)\n",
    "            self._get_cluster_signals()\n",
    "            self._assign_clusters()\n",
    "            perm_martin = self._get_total_performance()\n",
    "            self._perm_martins.append(perm_martin)\n",
    "\n",
    "\n",
    "    def _find_unique_patterns(self):\n",
    "        # Find unique pip patterns in data\n",
    "        self._unique_pip_indices.clear()\n",
    "        self._unique_pip_patterns.clear()\n",
    "        \n",
    "        last_pips_x = [0] * self._n_pips\n",
    "        for i in range(self._lookback - 1, len(self._data) - self._hold_period):\n",
    "            start_i = i - self._lookback + 1\n",
    "            window = self._data[start_i: i + 1]\n",
    "            pips_x, pips_y = find_pips(window, self._n_pips, 3)\n",
    "            pips_x = [j + start_i for j in pips_x]\n",
    "\n",
    "            # Check internal pips to see if it is the same as last\n",
    "            same = True\n",
    "            for j in range(1, self._n_pips - 1):\n",
    "                if pips_x[j] != last_pips_x[j]:\n",
    "                    same = False\n",
    "                    break\n",
    "            \n",
    "            if not same:\n",
    "                # Z-Score normalize pattern\n",
    "                pips_y = list((np.array(pips_y) - np.mean(pips_y)) / np.std(pips_y))\n",
    "                self._unique_pip_patterns.append(pips_y)\n",
    "                self._unique_pip_indices.append(i)\n",
    "\n",
    "            last_pips_x = pips_x\n",
    "\n",
    "\n",
    "    def _kmeans_cluster_patterns(self, amount_clusters):\n",
    "        # Cluster Patterns\n",
    "        initial_centers = kmeans_plusplus_initializer(self._unique_pip_patterns, amount_clusters).initialize()\n",
    "        kmeans_instance = kmeans(self._unique_pip_patterns, initial_centers)\n",
    "        kmeans_instance.process()\n",
    "\n",
    "        # Extract clustering results: clusters and their centers\n",
    "        self._pip_clusters = kmeans_instance.get_clusters()\n",
    "        self._cluster_centers = kmeans_instance.get_centers()\n",
    "\n",
    "    def _get_martin(self, rets: np.array):\n",
    "        rsum = np.sum(rets)\n",
    "        short = False\n",
    "        if rsum < 0.0:\n",
    "            rets *= -1\n",
    "            rsum *= -1\n",
    "            short = True\n",
    "\n",
    "        csum = np.cumsum(rets)\n",
    "        eq = pd.Series(np.exp(csum))\n",
    "        sumsq = np.sum( ((eq / eq.cummax()) - 1) ** 2.0 )\n",
    "        ulcer_index = (sumsq / len(rets)) ** 0.5\n",
    "        martin = rsum / ulcer_index\n",
    "        if short:\n",
    "            martin = -martin\n",
    "\n",
    "        return martin\n",
    "\n",
    "    def _get_cluster_signals(self):\n",
    "        self._cluster_signals.clear()\n",
    "\n",
    "        for clust in self._pip_clusters: # Loop through each cluster\n",
    "            signal = np.zeros(len(self._data))\n",
    "            for mem in clust: # Loop through each member in cluster\n",
    "                arr_i = self._unique_pip_indices[mem]\n",
    "                \n",
    "                # Fill signal with 1s following pattern identification\n",
    "                # for hold period specified\n",
    "                signal[arr_i: arr_i + self._hold_period] = 1. \n",
    "            \n",
    "            self._cluster_signals.append(signal)\n",
    "\n",
    "    def _assign_clusters(self):\n",
    "        self._selected_long.clear()\n",
    "        self._selected_short.clear()\n",
    "        \n",
    "        # Assign clusters to long/short/neutral\n",
    "        cluster_martins = []\n",
    "        for clust_i in range(len(self._pip_clusters)): # Loop through each cluster\n",
    "            sig = self._cluster_signals[clust_i]\n",
    "            sig_ret = self._returns * sig\n",
    "            martin = self._get_martin(sig_ret)\n",
    "            cluster_martins.append(martin)\n",
    "\n",
    "        best_long = np.argmax(cluster_martins)\n",
    "        best_short = np.argmin(cluster_martins)\n",
    "        self._selected_long.append(best_long)\n",
    "        self._selected_short.append(best_short)\n",
    "\n",
    "    def _get_total_performance(self):\n",
    "\n",
    "        long_signal = np.zeros(len(self._data))\n",
    "        short_signal = np.zeros(len(self._data))\n",
    "\n",
    "        for clust_i in range(len(self._pip_clusters)):\n",
    "            if clust_i in self._selected_long:\n",
    "                long_signal += self._cluster_signals[clust_i]\n",
    "            elif clust_i in self._selected_short:\n",
    "                short_signal += self._cluster_signals[clust_i]\n",
    "        \n",
    "        long_signal /= len(self._selected_long)\n",
    "        short_signal /= len(self._selected_short)\n",
    "        short_signal *= -1\n",
    "\n",
    "        self._long_signal = long_signal\n",
    "        self._short_signal = short_signal\n",
    "        rets = (long_signal + short_signal) * self._returns\n",
    "\n",
    "        martin = self._get_martin(rets)\n",
    "        return martin\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                           symbol      Open      High       Low     Close  \\\n",
      "datetime                                                                    \n",
      "2022-01-03 20:00:00+00:00  ADAUSD  1.329520  1.330997  1.311061  1.318366   \n",
      "2022-01-04 00:00:00+00:00  ADAUSD  1.320009  1.322727  1.295564  1.313108   \n",
      "2022-01-04 04:00:00+00:00  ADAUSD  1.313530  1.323658  1.306044  1.323658   \n",
      "2022-01-04 08:00:00+00:00  ADAUSD  1.323872  1.340571  1.319159  1.340263   \n",
      "2022-01-04 12:00:00+00:00  ADAUSD  1.340742  1.350000  1.328286  1.333430   \n",
      "...                           ...       ...       ...       ...       ...   \n",
      "2024-04-15 16:00:00+00:00  ADAUSD  0.467430  0.470767  0.439729  0.456116   \n",
      "2024-04-15 20:00:00+00:00  ADAUSD  0.455761  0.460011  0.450535  0.455779   \n",
      "2024-04-16 00:00:00+00:00  ADAUSD  0.461068  0.466945  0.453810  0.456417   \n",
      "2024-04-16 04:00:00+00:00  ADAUSD  0.457451  0.478100  0.445848  0.474656   \n",
      "2024-04-16 08:00:00+00:00  ADAUSD  0.474172  0.475073  0.467380  0.470228   \n",
      "\n",
      "                                 Volume  \n",
      "datetime                                 \n",
      "2022-01-03 20:00:00+00:00  2.139705e+06  \n",
      "2022-01-04 00:00:00+00:00  1.176578e+06  \n",
      "2022-01-04 04:00:00+00:00  2.794300e+05  \n",
      "2022-01-04 08:00:00+00:00  3.110431e+05  \n",
      "2022-01-04 12:00:00+00:00  1.224215e+06  \n",
      "...                                 ...  \n",
      "2024-04-15 16:00:00+00:00  3.271555e+06  \n",
      "2024-04-15 20:00:00+00:00  4.426307e+05  \n",
      "2024-04-16 00:00:00+00:00  1.662871e+06  \n",
      "2024-04-16 04:00:00+00:00  2.279699e+06  \n",
      "2024-04-16 08:00:00+00:00  5.806159e+05  \n",
      "\n",
      "[5000 rows x 6 columns]\n"
     ]
    }
   ],
   "source": [
    "from  helpers_db import get_engine, run_sql\n",
    "engine = get_engine()\n",
    "with engine.begin() as conn:\n",
    "  data = run_sql(conn, \"\"\"SELECT * FROM ticks_4h WHERE symbol='ADAUSD'\"\"\")\n",
    "  df = pd.DataFrame(data)\n",
    "  df.rename(columns={\"close\": \"Close\", \"open\": \"Open\", \"low\": \"Low\", \"high\": \"High\", \"volume\": \"Volume\", \"dt\": \"datetime\"}, inplace=True)\n",
    "  df.set_index(\"datetime\", inplace = True)\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12.388294186533157\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'\\n# Monte Carlo test, takes about an hour..\\npip_miner.train(arr, n_reps=100)\\n\\nplt.style.use(\\'dark_background\\')\\nactual_martin = pip_miner.get_fit_martin()\\nperm_martins = pip_miner.get_permutation_martins()\\nax = pd.Series(perm_martins).hist()\\nax.set_ylabel(\"# Of Permutations\")\\nax.set_xlabel(\"Martin Ratio\")\\nax.set_title(\"Permutation\\'s Martin Ratio BTC-USDT 1H 2018-2020\")\\nax.axvline(actual_martin, color=\\'red\\')\\n'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = df\n",
    "plt.style.use('dark_background')\n",
    "\n",
    "data = data[data.index < '01-01-2024']\n",
    "arr = data['Close'].to_numpy()\n",
    "pip_miner = PIPPatternMiner(n_pips=5, lookback=24, hold_period=6)\n",
    "pip_miner.train(arr, n_reps=-1)\n",
    "\n",
    "'''\n",
    "# Monte Carlo test, takes about an hour..\n",
    "pip_miner.train(arr, n_reps=100)\n",
    "\n",
    "plt.style.use('dark_background')\n",
    "actual_martin = pip_miner.get_fit_martin()\n",
    "perm_martins = pip_miner.get_permutation_martins()\n",
    "ax = pd.Series(perm_martins).hist()\n",
    "ax.set_ylabel(\"# Of Permutations\")\n",
    "ax.set_xlabel(\"Martin Ratio\")\n",
    "ax.set_title(\"Permutation's Martin Ratio BTC-USDT 1H 2018-2020\")\n",
    "ax.axvline(actual_martin, color='red')\n",
    "'''"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
